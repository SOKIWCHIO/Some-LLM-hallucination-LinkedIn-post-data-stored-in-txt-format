URL: https://www.linkedin.com/posts/giovanni-dantonio_%F0%9D%90%8B%F0%9D%90%8B%F0%9D%90%8C-%F0%9D%90%87%F0%9D%90%9A%F0%9D%90%A5%F0%9D%90%A5%F0%9D%90%AE%F0%9D%90%9C%F0%9D%90%A2%F0%9D%90%A7%F0%9D%90%9A%F0%9D%90%AD%F0%9D%90%A2%F0%9D%90%A8%F0%9D%90%A7%F0%9D%90%AC-%F0%9D%90%86%F0%9D%90%A8-activity-7371576784859066368-h_zB
Date: 2025-09-24
Author: Unknown

ğ‹ğ‹ğŒ ğ‡ğšğ¥ğ¥ğ®ğœğ¢ğ§ğšğ­ğ¢ğ¨ğ§ğ¬? ğ†ğ¨ğ¨ğ ğ¥ğ ğƒğğğ©ğŒğ¢ğ§ğ ğ¢ğ¬ ğ¡ğğ«ğ ğ­ğ¨ ğ¬ğ¨ğ¥ğ¯ğ ğ­ğ¡ğ ğ©ğ«ğ¨ğ›ğ¥ğğ¦.

I'm happy to share that one of the benchmarks I worked on this summer is now publicly available!

SimpleQA Verified: a new gold standard for LLM factuality! 

A paper by OpenAI made waves by analyzing the reasons behind LLM hallucinations. Our work aims to contribute to the solution.

Existing benchmarks can be noisy, making it difficult to track true modeling progress.

Building on the work on SimpleQA by Jason Wei, Karina Nguyen, and OpenAI at large, we built a more reliable and robust version of it at Google DeepMind.

Some highlights:

ğŸ”¢ Revamping how numeric questions are graded
ğŸ¤¯ Making the benchmark more challenging
ğŸ‘¥ De-duplicating semantically similar questions
âš–ï¸ Balancing topics and answer types to remove bias
âœ… Reconciling sources to ensure ground truths are correct
â€¦ and more

On both the old and verified SimpleQA benchmark, Gemini 2.5 Pro sets SOTA factuality scores. I guess it is a good model for enterprises :)

We're open-sourcing our work to help the community build more trustworthy AI. Feel free to explore the leaderboard, download the dataset, and read our technical report in the comments below! ğŸ‘‡

I'm excited to publicly share a small piece of my work from this summer. Thanks, Lukas, for believing in me!

Lukas Haas, Gal Yona, Sasha Goldshtein, Dipanjan Das | Google DeepMind, è°·æ­Œ Research