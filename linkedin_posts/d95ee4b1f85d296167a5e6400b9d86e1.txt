URL: https://www.linkedin.com/posts/pascale-fung-a3aa05139_hallulens-llm-hallucination-benchmark-activity-7324532270294347776-5yug
Date: 2025-09-24
Author: Unknown

话题标签
#Hallucination in LLMs has been a long standing challenge to trustworthiness of these otherwise ever more powerful models. Having studied its source and mitigation methods, it became apparent to us that we could never solve the problem if we go around in circles by conflating model "hallucination" with the "
话题标签
#factuality" of the answers. So we designed a 
话题标签
#benchmark that separates the two when evaluating models. We also designed a benchmark that cannot be easily saturated by fine-tuning on itself. 

 "HalluLens: LLM Hallucination Benchmark
Large language models (LLMs) often generate responses that deviate from user input or training data, a phenomenon known as "hallucination." These hallucinations undermine user trust and hinder the adoption of generative AI systems. Addressing hallucinations is essential for the advancement of LLMs. This paper introduces a comprehensive hallucination benchmark, incorporating both new extrinsic and existing intrinsic evaluation tasks, built upon clear taxonomy of hallucination. A major challenge in benchmarking hallucinations is the lack of a unified framework due to inconsistent definitions and categorizations. We disentangle LLM hallucination from "factuality," proposing a clear taxonomy that distinguishes between extrinsic and intrinsic hallucinations, to promote consistency and facilitate research. Extrinsic hallucinations, where the generated content is not consistent with the training data, are increasingly important as LLMs evolve. Our benchmark includes dynamic test set generation to mitigate data leakage and ensure robustness against such leakage. We also analyze existing benchmarks, highlighting their limitations and saturation. The work aims to: (1) establish a clear taxonomy of hallucinations, (2) introduce new extrinsic hallucination tasks, with data that can be dynamically regenerated to prevent saturation by leakage, (3) provide a comprehensive analysis of existing benchmarks, distinguishing them from factuality evaluations. "